#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»è¯¾è¡¨ZIPè§£ææ•™å¸ˆä¿¡æ¯ï¼Œæ‰¹é‡UPDATEåˆ°course_scoreè¡¨çš„c_teacherå­—æ®µã€‚
ç”¨æ³•: python import_teacher.py --zip <è¯¾è¡¨ZIPè·¯å¾„> [--workers N] [--dry-run]
"""
import os
import re
import argparse
import zipfile
import concurrent.futures
from collections import defaultdict
from sqlalchemy import create_engine, Column, String, Float
from sqlalchemy.orm import sessionmaker, declarative_base
from sqlalchemy.dialects.postgresql import insert as pg_insert
from sqlalchemy import SmallInteger

from parse_schedule import parse_html, normalize_punct


# è¿›ç¨‹æ±  workerï¼šæ¯ä¸ªå­è¿›ç¨‹æ‰“å¼€ä¸€æ¬¡ ZIPï¼Œå¤ç”¨å¥æŸ„
_zf = None

def _init_worker(zip_path):
    global _zf
    _zf = zipfile.ZipFile(zip_path, 'r')

def _parse_one(filename):
    html = _zf.read(filename).decode('utf-8', errors='ignore')
    return parse_html(html, filename)

# å°è¯•å¯¼å…¥é…ç½®
try:
    from config import DB_URI, DB_POOL_SIZE, DB_MAX_OVERFLOW, DB_POOL_RECYCLE
except ImportError:
    DB_URI = 'postgresql+psycopg2://user:pass@localhost:5432/cdut-score'
    DB_POOL_SIZE = 32
    DB_MAX_OVERFLOW = 64
    DB_POOL_RECYCLE = 3600

Base = declarative_base()

class CourseScore(Base):
    __tablename__ = 'course_score'
    s_id = Column(String(14), primary_key=True)
    c_term = Column(String(8), primary_key=True)
    c_name = Column(String(100), primary_key=True)
    c_score = Column(Float, nullable=False)
    c_type = Column(String(20), nullable=False, default='å¿…ä¿®')
    c_hours = Column(String(10), nullable=False)
    c_credit = Column(Float, nullable=False)
    c_pass = Column(SmallInteger, nullable=False)
    c_teacher = Column(String(200), nullable=True)


def term_display_to_db(term_display):
    """
    è¯¾è¡¨å­¦æœŸæ ¼å¼ â†’ æ•°æ®åº“ c_term æ ¼å¼
    '2025-2026å­¦å¹´ç¬¬ä¸€å­¦æœŸ' â†’ '202501'
    '2024-2025å­¦å¹´ç¬¬äºŒå­¦æœŸ' â†’ '202402'
    ç¼–ç è§„åˆ™ï¼šc_term = èµ·å§‹å¹´ä»½ + 01(ç§‹)/02(æ˜¥)
    """
    m = re.match(r'(\d{4})-\d{4}å­¦å¹´ç¬¬(ä¸€|äºŒ)å­¦æœŸ', term_display)
    if not m:
        return None
    year1 = m.group(1)
    semester = '01' if m.group(2) == 'ä¸€' else '02'
    return f"{year1}{semester}"


def main():
    parser = argparse.ArgumentParser(description='å¯¼å…¥è¯¾è¡¨æ•™å¸ˆä¿¡æ¯åˆ°æ•°æ®åº“')
    parser.add_argument('--zip', required=True, help='è¯¾è¡¨ZIPå‹ç¼©åŒ…è·¯å¾„')
    parser.add_argument('--workers', type=int, default=os.cpu_count(), help='å¹¶å‘è¿›ç¨‹æ•°ï¼ˆé»˜è®¤CPUæ ¸å¿ƒæ•°ï¼‰')
    parser.add_argument('--batch-size', type=int, default=10000, help='æ¯æ‰¹å†™å…¥æ¡æ•°')
    parser.add_argument('--dry-run', action='store_true', help='åªè§£æä¸å†™å…¥ï¼Œé¢„è§ˆç»“æœ')
    args = parser.parse_args()

    # 1. åˆ—å‡ºZIPä¸­æ‰€æœ‰HTMLæ–‡ä»¶å
    print(f"ğŸ“‚ åŠ è½½ ZIP: {args.zip}")
    with zipfile.ZipFile(args.zip, 'r') as zf_main:
        html_files = [f for f in zf_main.namelist() if f.endswith('.html')]
    total_files = len(html_files)
    print(f"   å…± {total_files} ä¸ª HTML æ–‡ä»¶")

    # 2. å¤šè¿›ç¨‹å¹¶å‘è§£æï¼ˆCPUå¯†é›†å‹ï¼Œç”¨ProcessPoolExecutorï¼‰
    update_records = []
    success = 0
    empty = 0
    fail = 0
    skip_term = 0

    print(f"ğŸ”„ ä½¿ç”¨ {args.workers} ä¸ªè¿›ç¨‹å¹¶å‘è§£æ...")
    with concurrent.futures.ProcessPoolExecutor(max_workers=args.workers, initializer=_init_worker, initargs=(args.zip,)) as executor:
        futures = {
            executor.submit(_parse_one, filename): filename
            for filename in html_files
        }
        count = 0
        for future in concurrent.futures.as_completed(futures):
            count += 1
            if count % 1000 == 0 or count == total_files:
                print(f"\r   è§£æè¿›åº¦: {count}/{total_files} ({count*100//total_files}%)", end="", flush=True)
            try:
                filename, student, courses = future.result()
                if not courses:
                    empty += 1
                    continue

                sid = student.get('student_id', '')
                term_display = student.get('term', '')
                if not sid or not term_display:
                    empty += 1
                    continue

                db_term = term_display_to_db(term_display)
                if not db_term:
                    skip_term += 1
                    continue

                for c in courses:
                    teacher_py = c.get('teacher_py', '')
                    if teacher_py:
                        update_records.append({
                            's_id': sid,
                            'c_term': db_term,
                            'c_name': normalize_punct(c['name']),
                            'c_score': 0, 'c_type': '', 'c_hours': '0',
                            'c_credit': 0, 'c_pass': 0,
                            'c_teacher': teacher_py,
                        })
                success += 1
            except Exception as e:
                fail += 1

    print(f"\nâœ… è§£æå®Œæˆ: æœ‰è¯¾ {success}, ç©º {empty}, å¤±è´¥ {fail}, å­¦æœŸæ— æ³•è½¬æ¢ {skip_term}")
    print(f"   å¾…å†™å…¥è®°å½•æ•°: {len(update_records)}")

    if not update_records:
        print("âš ï¸ æ²¡æœ‰å¯æ›´æ–°çš„è®°å½•")
        return

    # 3. é¢„è§ˆ
    print(f"\nğŸ“‹ é¢„è§ˆå‰ 10 æ¡:")
    for rec in update_records[:10]:
        print(f"   {rec['s_id']} | {rec['c_term']} | {rec['c_name']} | {rec['c_teacher']}")

    terms = defaultdict(int)
    for rec in update_records:
        terms[rec['c_term']] += 1
    print(f"\n   æŒ‰å­¦æœŸåˆ†å¸ƒ:")
    for term, cnt in sorted(terms.items()):
        print(f"     {term}: {cnt} æ¡")

    if args.dry_run:
        print("\nğŸ” dry-run æ¨¡å¼ï¼Œä¸å†™å…¥æ•°æ®åº“")
        return

    # 4. SQLAlchemy æ‰¹é‡ INSERT ... ON DUPLICATE KEY UPDATEï¼ˆå’Œ grade_manager ä¸€æ ·ï¼‰
    print(f"\nğŸ’¾ å¼€å§‹å†™å…¥æ•°æ®åº“...")
    engine = create_engine(DB_URI, pool_size=DB_POOL_SIZE,
                           max_overflow=DB_MAX_OVERFLOW, pool_recycle=DB_POOL_RECYCLE,
                           pool_pre_ping=True)
    Session = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    session = Session()

    try:
        total = len(update_records)
        batch_size = args.batch_size
        print(f"ğŸ“š æ­£åœ¨å†™å…¥æ•™å¸ˆä¿¡æ¯ ({total} æ¡)...")

        for i in range(0, total, batch_size):
            batch = update_records[i:i+batch_size]
            stmt = pg_insert(CourseScore).values(batch)
            update_stmt = stmt.on_conflict_do_update(
                index_elements=['s_id', 'c_term', 'c_name'],
                set_={'c_teacher': stmt.excluded.c_teacher}
            )
            session.execute(update_stmt)
            done = min(i + batch_size, total)
            print(f"\r   å†™å…¥è¿›åº¦: {done}/{total} ({done*100//total}%)", end="", flush=True)

        session.commit()
        print(f"\nâœ… å†™å…¥å®Œæˆ: å…± {total} æ¡")

    except Exception as e:
        session.rollback()
        print(f"\nâŒ å†™å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        session.close()
        engine.dispose()


if __name__ == '__main__':
    main()
